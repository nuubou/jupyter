{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロジスティック回帰\n",
    "\n",
    "## 概要\n",
    "\n",
    "### ロジスティック回帰とは\n",
    "\n",
    "ロジスティック回帰分析は目的変数が1となる確率を予測します。\n",
    "\n",
    "### ロジスティック回帰の活用例\n",
    "\n",
    "* キャンペーンの反応率\n",
    "* 土砂災害発生危険基準線の確率\n",
    "* 医療における症例の発生確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰モデル(2クラス分類)\n",
    "\n",
    "$$ \\sigma\\big( a \\big)  = \\frac{1}{1 + exp(-a)} $$\n",
    "\n",
    "$$ p \\big( C_{1} \\mid \\phi \\big) = y\\big( \\phi \\big) = \\sigma\\big( w^{T}\\phi \\big)  $$\n",
    "\n",
    "$$ p \\big( C_{1} \\mid \\phi \\big) = \\frac{1}{1 + exp(- w^{T}\\phi)} $$\n",
    "\n",
    "<div style=\"text-align: right;\">p204. 4.3.2 ロジスティック回帰</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最尤法を用いたパラメータ(w)決定\n",
    "\n",
    "### 交差エントロピー誤差関数(cross-entropy error function)\n",
    "\n",
    "$$ \\nabla E\\big(w\\big) = \\sum_{n=1}^{N} \\big( y_{n} - t_{n} \\big) \\phi_{n} $$\n",
    "\n",
    "### ニュートン-ラフソン法による w の更新\n",
    "\n",
    "$$ w^{(new)} = w^{(old)} - \\big( \\Phi^{T}R\\Phi \\big)^{-1}\\Phi^{T}\\big(y - t\\big) $$\n",
    "$$ = \\big( \\Phi^{T}R\\Phi \\big)^{-1} \\big\\{ \\Phi^{T}R\\Phi w^{(old)} - \\Phi^{T}(y - t) \\big\\} $$\n",
    "$$ = \\big( \\Phi^{T}R\\Phi \\big)^{-1}\\Phi^{T}Rz $$\n",
    "\n",
    "重み付き最小二乗問題に対する正規方程式の集合。\n",
    "\n",
    "#### NxN の対角行列R\n",
    "\n",
    "$$ R_{nn} = y_{n} \\big( 1 - y_{n} \\big) $$\n",
    "\n",
    "パラメータ・ベクトル w に依存しているので、wが新しくなるたびに重み付け行列Rを計算し直す必要がある。\n",
    "\n",
    "#### N次元ベクトルN\n",
    "\n",
    "$$ z = \\Phi w^{(old)} - R^{-1}\\big( y - t \\big)$$\n",
    "\n",
    "このアルゴリズムを反復再重み付け最小二乗法( *iterative reweighted least squares method* = **IRLS** )\n",
    "\n",
    "変数空間\n",
    "\n",
    "$$ a = w^{T}\\phi $$\n",
    "\n",
    "内の線形化された問題の解としてIRLSを解釈することができる。\n",
    "そのときzのn番目の要素に相当する\n",
    "\n",
    "$$z_{n}$$\n",
    "\n",
    "は、ロジスティックシグモイド関数を現在の点\n",
    "\n",
    "$$w^{(old)}$$\n",
    "\n",
    "の周りで局所線形近似して得られる空間での目的変数であると解釈できる。\n",
    "\n",
    "$$ a_{n} \\big(w\\big)\\simeq a_{n} \\big( w^{(old)} \\big) + \\frac{da_{n}}{dy_{n}}|_{w^{(old)}}\\big( t_{n} - y_{n} \\big) $$\n",
    "$$ = \\phi_{n}^{T}w^{(old)} - \\frac{(y_{n} - t_{n})}{y_{n}(1 - y_{n})} = z_{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰モデル(多クラス分類)\n",
    "\n",
    "多クラスの分布に対して、事後確率が特徴変換のソフトマックス変換で与えられる。\n",
    "\n",
    "### 事後確率\n",
    "\n",
    "$$ p \\big( C_{k} \\mid \\phi \\big) = y_{k} \\big( \\phi \\big) = \\frac{exp(a_{k})}{\\sum_{j}exp(a_{j})} $$\n",
    "\n",
    "### 活性\n",
    "\n",
    "$$ a_{k} = w_{k}^{T}\\phi. $$\n",
    "\n",
    "### 最尤法を用いてパラメータwを決定する\n",
    "\n",
    "すべての活性化関数に関するyの微分が必要となる。\n",
    "\n",
    "$$ \\frac{\\partial y_{k}}{\\partial a{j}} = y_{k} \\big( I_{kj} - y{j} \\big)  (4.106)$$\n",
    "\n",
    "I は単位行列の要素。\n",
    "ここから尤度関数を出して式変形すると、多クラス分類問題に対する *交差エントロピー誤差関数*  になる。\n",
    "\n",
    "### 多クラス交差エントロピー誤差関数と勾配\n",
    "\n",
    "#### 多クラス交差エントロピー誤差関数\n",
    "\n",
    "$$ E\\big( w_{1}, ... , w_{K} \\big) = - \\ln p \\big( T \\mid w_{1}, ... , w_{K} \\big) = - \\sum_{n=1}^{N} \\sum_{k=1}^{K} t_{nk} \\ln y_{nk} $$\n",
    "\n",
    "#### 勾配\n",
    "\n",
    "ソフトマックス関数の微分に対する結果(4.106)を使う。\n",
    "\n",
    "$$ \\nabla E \\big( w_{1}, ... , w_{K} \\big) = \\sum_{n=1}^{N} \\big( y_{nj} - t{nj} \\big) $$\n",
    "\n",
    "ここでは\n",
    "$$ \\sum_{k} t_{nk} = 1 $$\n",
    "を使っている。\n",
    "\n",
    "---\n",
    "\n",
    "あるデータ n でのパラメータ・ベクトル *w* に関する線形回帰モデルの対数尤度関数の微分は、「誤差」 *(yn-tn)* と特徴ベクトル *Φn* との積になる。\n",
    "同様に他クラス交差エントロピー誤差関数とソフトマックス活性化関数に対しても、「誤差」 *(yn-tn)* と特徴ベクトル *Φn* との積 という式が得られる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考書籍、ページ\n",
    "\n",
    "* シュプリンガー パターン認識と機械学習\n",
    "* [ロジスティック回帰分析](http://heartland.geocities.jp/ecodata222/ed/edj1-2-1-2.html)\n",
    "* [確率密度比を用いた新しい機械学習アルゴリズム](https://www.google.com/url?q=http://www.ocw.titech.ac.jp/index.php%3Fmodule%3DGeneral%26action%3DDownLoad%26file%3D201027244-14-1-34.pdf%26type%3Dcal%26JWC%3D201027244&sa=U&ved=0ahUKEwihq_fl-LXOAhUJL8AKHT3FB4kQFggEMAA&client=internal-uds-cse&usg=AFQjCNGkrPBUHWw-gkJtPKE2EiTRjN7XFA)\n",
    "* [TensorFlow-Examples](https://github.com/aymericdamien/TensorFlow-Examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Board\n",
    "\n",
    "```\n",
    "python $PYTHON_PACKAGES/tensorflow/tensorboard/tensorboard.py --logdir=/tmp/mnist_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手書きの数字画像を訓練データに使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784], name=\"x-input\") # mnist data image of shape 28*28=784\n",
    "W = tf.Variable(tf.zeros([784, 10]), name=\"weights\")\n",
    "b = tf.Variable(tf.zeros([10]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 活性化関数の定義\n",
    "\n",
    "要はモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 活性化関数\n",
    "with tf.name_scope(\"Wx_b\") as scope:\n",
    "    y = tf.nn.softmax( tf.matmul(x, W) + b )\n",
    "\n",
    "# matmulは行列積を計算する。↑は内積を計算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder( tf.float32, [None,10], name=\"y-input\" )  # 0〜9 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for TensorBoard\n",
    "w_hist = tf.histogram_summary(\"weights\", W)\n",
    "b_hist = tf.histogram_summary(\"biases\", b)\n",
    "y_hist = tf.histogram_summary(\"y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数の定義\n",
    "\n",
    "交差エントロピー誤差関数のエラーを最小化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 損失関数\n",
    "with tf.name_scope(\"xentropy\") as scope:\n",
    "    cross_entropy = -tf.reduce_sum( y_*tf.log(y) )\n",
    "    ce_summ = tf.scalar_summary( \"cross entropy\", cross_entropy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## オプティマイザの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer( learning_rate ).minimize( cross_entropy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0001 cost= 42.460622241\n",
      "Epoch: 0002 cost= 31.676059714\n",
      "Epoch: 0003 cost= 30.587358395\n",
      "Epoch: 0004 cost= 29.562264427\n",
      "Epoch: 0005 cost= 29.045376204\n",
      "Epoch: 0006 cost= 28.798553118\n",
      "Epoch: 0007 cost= 28.545274428\n",
      "Epoch: 0008 cost= 28.201118325\n",
      "Epoch: 0009 cost= 28.095019536\n",
      "Epoch: 0010 cost= 27.824128557\n",
      "Epoch: 0011 cost= 27.871425612\n",
      "Epoch: 0012 cost= 27.589665217\n",
      "Epoch: 0013 cost= 27.316248264\n",
      "Epoch: 0014 cost= 27.571409637\n",
      "Epoch: 0015 cost= 27.225286407\n",
      "Epoch: 0016 cost= 27.038180164\n",
      "Epoch: 0017 cost= 27.032229052\n",
      "Epoch: 0018 cost= 27.101991416\n",
      "Epoch: 0019 cost= 26.799124130\n",
      "Epoch: 0020 cost= 26.858826623\n",
      "Epoch: 0021 cost= 26.571702370\n",
      "Epoch: 0022 cost= 26.657822528\n",
      "Epoch: 0023 cost= 26.531379691\n",
      "Epoch: 0024 cost= 26.544153503\n",
      "Epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0025 cost= 26.540901189\n",
      "Optimization Finished!\n",
      "Accuracy: 0.896\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run( init )\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int( mnist.train.num_examples / batch_size )\n",
    "\n",
    "        for i in range( total_batch ):\n",
    "            # feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # fit\n",
    "            _, c = sess.run( [optimizer, cross_entropy], feed_dict={x: batch_xs, y_: batch_ys} )\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    with tf.name_scope(\"test\") as scope:\n",
    "        # Test model\n",
    "        correct_prediction = tf.equal( tf.argmax(y, 1), tf.argmax(y_, 1) )\n",
    "        # accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        #accuracy = tf.reduce_mean(　tf.cast(correct_prediction, tf.float32)　)\n",
    "        accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy)\n",
    "        print \"Accuracy:\", accuracy.eval({x: mnist.test.images[:3000], y_: mnist.test.labels[:3000]})\n",
    "\n",
    "        # 全ての要約をマージしてそれらを /tmp/mnist_logs に書き出します。\n",
    "        merged = tf.merge_all_summaries()\n",
    "        writer = tf.train.SummaryWriter(\"/tmp/mnist_logs\", sess.graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
