{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロジスティック回帰\n",
    "\n",
    "## 概要\n",
    "\n",
    "### ロジスティック回帰とは\n",
    "\n",
    "ロジスティック回帰分析は目的変数が1となる確率を予測します。\n",
    "\n",
    "### ロジスティック回帰の活用例\n",
    "\n",
    "* キャンペーンの反応率\n",
    "* 土砂災害発生危険基準線の確率\n",
    "* 医療における症例の発生確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰モデル(2クラス分類)\n",
    "\n",
    "$$ \\sigma\\big( a \\big)  = \\frac{1}{1 + exp(-a)} $$\n",
    "\n",
    "$$ p \\big( C_{1}|\\phi \\big) = y\\big( \\phi \\big) = \\sigma\\big( w^{T}\\phi \\big)  $$\n",
    "\n",
    "$$ p \\big( C_{1}|\\phi \\big) = \\frac{1}{1 + exp(- w^{T}\\phi)} $$\n",
    "\n",
    "<div style=\"text-align: right;\">p204. 4.3.2 ロジスティック回帰</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最尤法を用いたパラメータ(w)決定\n",
    "\n",
    "### 交差エントロピー誤差関数(cross-entropy error function)\n",
    "\n",
    "$$ \\nabla E\\big(w\\big) = \\sum_{n=1}^{N} \\big( y_{n} - t_{n} \\big) \\phi_{n} $$\n",
    "\n",
    "### ニュートン-ラフソン法による w の更新\n",
    "\n",
    "$$ w^{(new)} = w^{(old)} - \\big( \\Phi^{T}R\\Phi \\big)^{-1}\\Phi^{T}\\big(y - t\\big) $$\n",
    "$$ = \\big( \\Phi^{T}R\\Phi \\big)^{-1} \\big\\{ \\Phi^{T}R\\Phi w^{(old)} - \\Phi^{T}(y - t) \\big\\} $$\n",
    "$$ = \\big( \\Phi^{T}R\\Phi \\big)^{-1}\\Phi^{T}Rz $$\n",
    "\n",
    "重み付き最小二乗問題に対する正規方程式の集合。\n",
    "\n",
    "#### NxN の対角行列R\n",
    "\n",
    "$$ R_{nn} = y_{n} \\big( 1 - y_{n} \\big) $$\n",
    "\n",
    "パラメータ・ベクトル w に依存しているので、wが新しくなるたびに重み付け行列Rを計算し直す必要がある。\n",
    "\n",
    "#### N次元ベクトルN\n",
    "\n",
    "$$ z = \\Phi w^{(old)} - R^{-1}\\big( y - t \\big)$$\n",
    "\n",
    "このアルゴリズムを反復再重み付け最小二乗法( *iterative reweighted least squares method* = **IRLS** )\n",
    "\n",
    "変数空間\n",
    "\n",
    "$$ a = w^{T}\\phi $$\n",
    "\n",
    "内の線形化された問題の解としてIRLSを解釈することができる。\n",
    "そのときzのn番目の要素に相当する\n",
    "\n",
    "$$z_{n}$$\n",
    "\n",
    "は、ロジスティックシグモイド関数を現在の点\n",
    "\n",
    "$$w^{(old)}$$\n",
    "\n",
    "の周りで局所線形近似して得られる空間での目的変数であると解釈できる。\n",
    "\n",
    "$$ a_{n} \\big(w\\big)\\simeq a_{n} \\big( w^{(old)} \\big) + \\frac{da_{n}}{dy_{n}}|_{w^{(old)}}\\big( t_{n} - y_{n} \\big) $$\n",
    "$$ = \\phi_{n}^{T}w^{(old)} - \\frac{(y_{n} - t_{n})}{y_{n}(1 - y_{n})} = z_{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考書籍、ページ\n",
    "\n",
    "* シュプリンガー パターン認識と機械学習\n",
    "* [ロジスティック回帰分析](http://heartland.geocities.jp/ecodata222/ed/edj1-2-1-2.html)\n",
    "* [確率密度比を用いた新しい機械学習アルゴリズム](https://www.google.com/url?q=http://www.ocw.titech.ac.jp/index.php%3Fmodule%3DGeneral%26action%3DDownLoad%26file%3D201027244-14-1-34.pdf%26type%3Dcal%26JWC%3D201027244&sa=U&ved=0ahUKEwihq_fl-LXOAhUJL8AKHT3FB4kQFggEMAA&client=internal-uds-cse&usg=AFQjCNGkrPBUHWw-gkJtPKE2EiTRjN7XFA)\n",
    "* [TensorFlow-Examples](https://github.com/aymericdamien/TensorFlow-Examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Board\n",
    "\n",
    "```\n",
    "python $PYTHON_PACKAGES/tensorflow/tensorboard/tensorboard.py --logdir=/tmp/mnist_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手書きの数字画像を訓練データに使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784], name=\"x-input\") # mnist data image of shape 28*28=784\n",
    "W = tf.Variable(tf.zeros([784, 10]), name=\"weights\")\n",
    "b = tf.Variable(tf.zeros([10]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 活性化関数の定義\n",
    "\n",
    "要はモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 活性化関数\n",
    "with tf.name_scope(\"Wx_b\") as scope:\n",
    "    y = tf.nn.softmax( tf.matmul(x, W) + b )\n",
    "\n",
    "# matmulは行列積を計算する。↑は内積を計算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder( tf.float32, [None,10], name=\"y-input\" )  # 0〜9 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for TensorBoard\n",
    "w_hist = tf.histogram_summary(\"weights\", W)\n",
    "b_hist = tf.histogram_summary(\"biases\", b)\n",
    "y_hist = tf.histogram_summary(\"y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数の定義\n",
    "\n",
    "交差エントロピー誤差関数のエラーを最小化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 損失関数\n",
    "with tf.name_scope(\"xentropy\") as scope:\n",
    "    cross_entropy = -tf.reduce_sum( y_*tf.log(y) )\n",
    "    ce_summ = tf.scalar_summary( \"cross entropy\", cross_entropy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## オプティマイザの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer( learning_rate ).minimize( cross_entropy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0001 cost= 42.460622241\n",
      "Epoch: 0002 cost= 31.676059714\n",
      "Epoch: 0003 cost= 30.587358395\n",
      "Epoch: 0004 cost= 29.562264427\n",
      "Epoch: 0005 cost= 29.045376204\n",
      "Epoch: 0006 cost= 28.798553118\n",
      "Epoch: 0007 cost= 28.545274428\n",
      "Epoch: 0008 cost= 28.201118325\n",
      "Epoch: 0009 cost= 28.095019536\n",
      "Epoch: 0010 cost= 27.824128557\n",
      "Epoch: 0011 cost= 27.871425612\n",
      "Epoch: 0012 cost= 27.589665217\n",
      "Epoch: 0013 cost= 27.316248264\n",
      "Epoch: 0014 cost= 27.571409637\n",
      "Epoch: 0015 cost= 27.225286407\n",
      "Epoch: 0016 cost= 27.038180164\n",
      "Epoch: 0017 cost= 27.032229052\n",
      "Epoch: 0018 cost= 27.101991416\n",
      "Epoch: 0019 cost= 26.799124130\n",
      "Epoch: 0020 cost= 26.858826623\n",
      "Epoch: 0021 cost= 26.571702370\n",
      "Epoch: 0022 cost= 26.657822528\n",
      "Epoch: 0023 cost= 26.531379691\n",
      "Epoch: 0024 cost= 26.544153503\n",
      "Epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0025 cost= 26.540901189\n",
      "Optimization Finished!\n",
      "Accuracy: 0.896\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run( init )\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int( mnist.train.num_examples / batch_size )\n",
    "\n",
    "        for i in range( total_batch ):\n",
    "            # feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # fit\n",
    "            _, c = sess.run( [optimizer, cross_entropy], feed_dict={x: batch_xs, y_: batch_ys} )\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    with tf.name_scope(\"test\") as scope:\n",
    "        # Test model\n",
    "        correct_prediction = tf.equal( tf.argmax(y, 1), tf.argmax(y_, 1) )\n",
    "        # accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        #accuracy = tf.reduce_mean(　tf.cast(correct_prediction, tf.float32)　)\n",
    "        accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy)\n",
    "        print \"Accuracy:\", accuracy.eval({x: mnist.test.images[:3000], y_: mnist.test.labels[:3000]})\n",
    "\n",
    "        # 全ての要約をマージしてそれらを /tmp/mnist_logs に書き出します。\n",
    "        merged = tf.merge_all_summaries()\n",
    "        writer = tf.train.SummaryWriter(\"/tmp/mnist_logs\", sess.graph_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分散TensorFlow\n",
    "\n",
    "これらを分散環境で実行してみる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\"]})\n",
    "server = tf.train.Server(cluster, job_name=\"local\", task_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device(tf.train.replica_device_setter(\n",
    "    worker_device=\"/job:local/task:0\",\n",
    "    cluster=cluster)):\n",
    " \n",
    "    global_step = tf.Variable(0)\n",
    " \n",
    "    with tf.name_scope(\"dist_train\") as scope:\n",
    "        optimizer2 = tf.train.GradientDescentOptimizer( learning_rate ).minimize( cross_entropy, global_step=global_step )    \n",
    " \n",
    "    saver = tf.train.Saver()\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "    init_op = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 訓練を監視するスーパーバイザを作成\n",
    "sv = tf.train.Supervisor(is_chief=1,\n",
    "                             logdir=\"/tmp/train_logs\",\n",
    "                             init_op=init_op,\n",
    "                             summary_op=summary_op,\n",
    "                             saver=saver,\n",
    "                             global_step=global_step,\n",
    "                             save_model_secs=600)\n",
    " \n",
    "# スーパーバイザはセッション初期化をケアしてチェックポイントから復旧します。\n",
    "sess = sv.prepare_or_wait_for_session(server.target)\n",
    " \n",
    "# 入力パイプラインに対してキュー・ランナーを開始します（もしあれば）。\n",
    "sv.start_queue_runners(sess)\n",
    "\n",
    "# スーパーバイザがシャットダウンするまでループします（あるいは 1000000 ステップが完了するまで）。\n",
    "step = 0\n",
    "while not sv.should_stop() and step < 50000:\n",
    "    # 訓練ステップを非同期に実行します。\n",
    "    # *同期* 訓練をどのように遂行するかについての追加の詳細情報は `tf.train.SyncReplicasOptimizer` を参照。\n",
    "\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    # fit\n",
    "    _, step = sess.run([optimizer2, global_step], feed_dict={x: batch_xs, y_: batch_ys} )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
