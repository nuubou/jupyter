{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed TensorFlow ( 分散TensorFlow )\n",
    "\n",
    "## Distributed TensorFlowでロジスティック回帰\n",
    "\n",
    "TensorFlow0.8から並列分散処理がサポートされるようになりました。  \n",
    "単一マシンで実行していたロジスティック回帰を複数マシンで並列実行してみます。  \n",
    "\n",
    "### 環境\n",
    "\n",
    "Dockerにパラメータ・サーバ2台(`ps`)、 ワーカー・サーバ2台(`worker`)を立てて実行しました。  \n",
    "使用したDockerイメージは Docker Hubの [tensorflow/tensorflow](https://hub.docker.com/r/tensorflow/tensorflow/)です。  \n",
    "TensorFlow のバージョンは`0.9.0`を使っています。  \n",
    "\n",
    "### 参考資料\n",
    "\n",
    "* [公式のDistributed TensorFlow](https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html)\n",
    "TensorFlowを分散処理させるスケルトンが掲載されています。\n",
    "\n",
    "* [DISTRIBUTED TENSORFLOW EXAMPLE](http://ischlag.github.io/2016/06/12/async-distributed-tensorflow/)\n",
    "TensorFlowの並列実行と統合の仕組みが図解されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*- encoding: utf-8 -*-\n",
    "# vim: tabstop=8 expandtab shiftwidth=4 softtabstop=4\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Flags for defining the tf.train.ClusterSpec\n",
    "tf.app.flags.DEFINE_string(\"ps_hosts\", \"\",\n",
    "                           \"Comma-separated list of hostname:port pairs\")\n",
    "tf.app.flags.DEFINE_string(\"worker_hosts\", \"\",\n",
    "                           \"Comma-separated list of hostname:port pairs\")\n",
    "\n",
    "# Flags for defining the tf.train.Server\n",
    "tf.app.flags.DEFINE_string(\"job_name\", \"\", \"One of 'ps', 'worker'\")\n",
    "tf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# config\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "board_path = \"/var/data/shared/board\"\n",
    "\n",
    "def main(_):\n",
    "\n",
    "    ps_hosts = FLAGS.ps_hosts.split(\",\")\n",
    "    worker_hosts = FLAGS.worker_hosts.split(\",\")\n",
    "    worker_num = len(worker_hosts)\n",
    "\n",
    "    # cluster を作成します。\n",
    "    cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\n",
    "\n",
    "    # ローカル・タスクを実行するサーバを開始します。\n",
    "    server = tf.train.Server(cluster,\n",
    "                             job_name=FLAGS.job_name,\n",
    "                             task_index=FLAGS.task_index)\n",
    "\n",
    "    mnist    = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    is_chief = (FLAGS.task_index == 0)\n",
    "\n",
    "    if FLAGS.job_name == \"ps\":\n",
    "        server.join()\n",
    "    elif FLAGS.job_name == \"worker\":\n",
    "\n",
    "        # Between-graph replication\n",
    "        with tf.device(tf.train.replica_device_setter(\n",
    "             worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n",
    "             cluster=cluster)):\n",
    "\n",
    "            # 更新数のカウンター\n",
    "            global_step = tf.get_variable('global_step', [],\n",
    "                                          initializer = tf.constant_initializer(0),\n",
    "                                          trainable = False)\n",
    "\n",
    "\n",
    "            with tf.name_scope('input'):\n",
    "                x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x-input\")  # mnist data image of shape 28*28=784\n",
    "                y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"y-input\")  # 0〜9 10 classes\n",
    "\n",
    "            with tf.name_scope(\"weights\"):\n",
    "                W = tf.Variable(tf.zeros([784, 10]))\n",
    "\n",
    "            with tf.name_scope(\"biases\"):\n",
    "                b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "            with tf.name_scope(\"softmax\"):\n",
    "                y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "            with tf.name_scope('cross_entropy'):\n",
    "                #cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "                cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "            # optimizer\n",
    "            with tf.name_scope('train'):\n",
    "                grad_op = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "                # SyncReplicasOptimizerを使うと、同期的に勾配を集約してオプティマイザに渡すことができます。\n",
    "                rep_op = tf.train.SyncReplicasOptimizer(grad_op,\n",
    "                                                    replicas_to_aggregate=worker_num,\n",
    "                                                    replica_id=FLAGS.task_index,\n",
    "                                                    total_num_replicas=worker_num,\n",
    "                                                    use_locking=True)\n",
    "                train_op = rep_op.minimize(cross_entropy, global_step=global_step)\n",
    "                #train_op = grad_op.minimize(cross_entropy, global_step=global_step)\n",
    "\n",
    "            init_token_op      = rep_op.get_init_tokens_op()\n",
    "            chief_queue_runner = rep_op.get_chief_queue_runner()\n",
    "\n",
    "            with tf.name_scope('Accuracy'):\n",
    "                # accuracy\n",
    "                correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "                accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "            tf.scalar_summary(\"cost\", cross_entropy)\n",
    "            tf.scalar_summary(\"accuracy\", accuracy)\n",
    "\n",
    "            #saver = tf.train.Saver()\n",
    "            summary_op = tf.merge_all_summaries()\n",
    "            init_op = tf.initialize_all_variables()\n",
    "            print(\"Variables initialized ...\")\n",
    "\n",
    "        sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),\n",
    "                                 global_step=global_step,\n",
    "                                 init_op=init_op)\n",
    "\n",
    "        begin_time = time.time()\n",
    "        frequency = 100\n",
    "        with sv.prepare_or_wait_for_session(server.target, config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "            # is chief\n",
    "            if is_chief:\n",
    "                sv.start_queue_runners(sess, [chief_queue_runner])\n",
    "                sess.run(init_token_op)\n",
    "\n",
    "            writer = tf.train.SummaryWriter(board_path, graph=tf.get_default_graph())\n",
    "\n",
    "            start_time = time.time()\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                batch_count = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "                count = 0\n",
    "                for i in range(batch_count):\n",
    "                    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                    if i % worker_num == FLAGS.task_index:\n",
    "                        continue\n",
    "\n",
    "                    _, cost, summary, step = sess.run(\n",
    "                             [train_op, cross_entropy, summary_op, global_step],\n",
    "                             feed_dict={x: batch_x, y_: batch_y})\n",
    "                    writer.add_summary(summary, step)\n",
    "\n",
    "                    count += 1\n",
    "                    if count % frequency == 0 or i+1 == batch_count:\n",
    "                        elapsed_time = time.time() - start_time\n",
    "                        start_time   = time.time()\n",
    "                        print(\"Step: %d,\"           % (step+1),\n",
    "                              \" Epoch: %2d,\"        % (epoch+1),\n",
    "                              \" Batch: %3d of %3d,\" % (i+1, batch_count),\n",
    "                              \" Cost: %.4f,\"        % cost,\n",
    "                              \" AvgTime: %3.2fms\"   % float(elapsed_time*1000/frequency))\n",
    "                        count = 0\n",
    "\n",
    "            print(\"Test-Accuracy: %2.2f\" % sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "            print(\"Total Time: %3.2fs\"   % float(time.time() - begin_time))\n",
    "            print(\"Final Cost: %.4f\"     % cost)\n",
    "\n",
    "        #sv.stop()\n",
    "        if is_chief:\n",
    "            sv.request_stop()\n",
    "        else:\n",
    "            sv.stop()\n",
    "        print(\"done\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行\n",
    "\n",
    "<img src=\"./images/distributed_tensorflow_run.png\" />\n",
    "\n",
    "### コンテナの状態\n",
    "\n",
    "<img src=\"./images/distributed_tensorflow_top.png\" />\n",
    "\n",
    "全コンテナで python が動いていることが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
